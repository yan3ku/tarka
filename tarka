#!/bin/sh
#
# incremental backups using tar and rsync
# works transparently over SSH by mounting with sshfs
# unencrypted files are never exposed on the remote system
# root privileges are required to preserve permissions (see tar man page for -p)
#
# TODO: cleanup
#
#set -x

passprompt() {
    stty -echo
    printf "Backup password: "
    read pass
    stty echo
    echo
}

cleanup() {
    echo "-- cleaning up"
    rm -f "$repo/.lock"
    rm -f "$repo/*.tar"
}

parse() { # parse backup file name and their metadata eg:
    # home~yaneko~devel~tarka~test-in~2025-10-16__16-22.39=fb63256f!0.tar.gpg
    set -- "$(basename "$1")"
    psrc="$(echo "~${1%~*}~" | tr '~' '/')"
    pmeta="${1##*~}"

    pdate="${pmeta%=*}"
    phash="${pmeta##*=}"
    phash="${phash%!*}"
    pnr="${pmeta#*!}"
    pnr="${pnr%--*}"
    pnr="${pnr%%.*}"
    ptag="${pmeta#*!}"
    ptag="${ptag#*--}"
    ptag="${ptag%%.*}"
    test "$pmeta" = "${pmeta#*--*}" && ptag=""

    # echo "psrc $psrc"
    # echo "date $pdate"
    # echo "hash $phash"
    # echo "pnr  $pnr"
    # echo "ptag $ptag"
}

mangle() {  # mangle directory to use as backup filename
    mangle="${1%/}"
    mangle="$(echo "${mangle#/}" | tr '/' '~')"
    printf "%s" "$mangle"
}

realmangle() {
    mangle "$(realpath "$1")"
}

latest() { # latest backup for directory
    latest=""
    for i in "$repo"/"$(realmangle $1)"*; do
        if test "${i##*.}" != snar; then
            latest="$i"
        fi
    done
    printf "%s" "$latest"
}


merge_dir() { # path hash | directory for merging tars aka extract dir
    printf "%s" "${fetchdir}/$(realmangle "$1")~$2"
}

dst() { # destination name for new backup
    printf "%s" "$(realmangle $src)~${date}=${hash}!${nr}${tag:+--}${tag}"
}

exits() {
    printf "%s; exiting\n" "--! $1" >&2
    exit 1
}

encrypt() {
    gpg -q --batch --passphrase "$pass" --symmetric --cipher-algo AES256 "$@" || exits "gpg encrypt error"
}

isthere() {
    for i in "$repo"/"$(realmangle $1)"*"$2"*.gpg; do
        test -e "$i" || exits "backup for $1 $2 doesn't exist"
        break
    done
}

fetch() { # fetches from sshfs
    [ "$repo" = "$fetchdir" ] && return
    echo "-- fetch"
    for i in "$repo"/"$(realmangle $1)"*"$2"*.gpg; do
        test -e "$i" || exits "backup for $1 $2 doesn't exist"
        parse "$i"
        test "$pnr" -gt "${3-2137}" && break
        echo "$i"
        sync "$i" "$fetchdir/${i#$repo}" || exits "failed fetching $i"
    done
}

ungpg() {
    echo "-- ungpg"
    for i in "$fetchdir"/"$(realmangle $1)"*"$2"*.gpg; do
        parse "$i"
        test "$pnr" -gt "${3-2137}" && break
        echo "$i..."
        gpg -q --batch --passphrase "$pass" --output "${i%.gpg}" --decrypt "$i" || exits "gpg decrypt error"
    done
}

untar() {
    echo "-- untar"
    for i in "$fetchdir"/"$(realmangle $1)"*"$2"*.tar; do
        parse "$i"
        test "$pnr" -gt "${3-2137}" && break
        echo "$i..."
        tar -xpf "$i" -C "$fetchdir/" -G || exits "error untaring archive "$i""
        rm "$i"
    done
    test -e "$(merge_dir "$1" "$2")" || exits "assertion failed; merge directory is absent"
}

rand() {
    tr -dc a-z0-9 </dev/urandom | head -c 8
}

genhash() { # each set of incremental backups is grouped by hash
    hash=
    while test -z "$hash"; do
        rand="$(rand)"
        for i in "$repo/$(realmangle $src)"*"$rand"*.gpg; do
            test -e "$i" || hash="$rand"
            break
        done
    done
    printf "%s" "$hash"
}

list() {
    fmt="%-40s\t%12s %-5s\t%8s %02s\t%s\n"
    printf "$fmt"  "src" "day" "hour" "hash" "nr" "tag"
    for i in "$repo/${1+$(realmangle $1)}"*.gpg; do
        test -e "$i" || break
        parse "$i"
        pdate="${pdate%.*}"
        pday="${pdate%__*}"
        phour="${pdate#*__}"
        printf "$fmt" "$psrc" "$pday" "$phour" "$phash" "$pnr" "$ptag"
    done
}

sync() {
    rsync "${3--q}" -az --delete  "${1}" "${2}" #--exclude-from="$0-ignore"
}

targ() { # tar with -g
    snar="$repo/~${1#$fetchdir/}.snar"
    test "$isfull" -eq 0 && ! test -e "$snar" && exits "snar at $snar doesn't exist"
    echo "-- tar with $snar..."
    tar -cpf "${2}.tar" "${1}" -g  "$snar" -P --lzma --xform="s|^${fetchdir}/||" || exits "archiving $1 failed"
}

usage() {
    cat >&2 <<EOF
$0 cmd repo args
cmd:
    full
    incremental
    list
    restore
EOF
    exit 1
}

is_repo() {
    if ! test -e "$repo/.repo"; then
        echo "-- not backup repository; exiting" >&2
        usage
    fi
}

info_header() {
    printf "%-10s : %s\n" "repo" "$repo"
    printf "%-10s : %s\n" "fetch" "$fetchdir"
    printf "%-10s : %s\n" "merge" "$xdir"
    printf "%-10s : %s\n" "dest" "$(dst)"
    test -n "$latest" && printf "%-10s : %s\n" "latest" "$latest"
    echo "----------"
}

restore() { # src hash
    test -n "$1" || usage
    test -n "$2" || usage

    src="$(realpath "$1")"
    hash="$2"
    nr="$3"
    xdir="$(merge_dir "$src" "$hash")/"

    isthere "$src" "$hash"
    info_header # debug info
    if test -e "$src"; then
        read -p "$src will be overwritten; continue? (yes/n): " choice
        test "$choice" != "yes" && exit 0
    fi
    passprompt
    fetch "$src" "$hash" "$nr"
    ungpg "$src" "$hash" "$nr"
    untar "$src" "$hash" "$nr"
    echo "-- restore $src"
    sync "$xdir" "$src" -v
    rm -r "$xdir"
}

backup() {
    test -n "$1" || usage

    src="$(realpath $1)"
    tag=${2:-}
    # %S is needed for correct ordering just in case of multiple backups in the same minut
    date=$(date +'%Y-%m-%d__%H-%M.%S')
    latest=$(latest "$src")

    if test "$isfull" -eq 1 || test ! -e "$latest"; then
        isfull=1
        hash="$(genhash)"
        nr="0"
    else
        parse "$latest"
        hash="$phash"
        nr="$((pnr+1))"
    fi

    mkdir -p "$fetchdir"
    xdir=$(merge_dir "$src" "$hash") # target for sync and the tar source

    isthere "$src" "$hash"
    info_header # debug info
    passprompt
    if test "$isfull" -eq 0; then
        fetch "$src" "$hash"
        ungpg "$src" "$hash"
        untar "$src" "$hash"
    fi
    echo "-- sync fetch dir"
    sync "$src/" "$xdir"
    targ "$xdir" "$fetchdir/$(dst)"
    encrypt "$fetchdir/$(dst)".tar
    echo "-- sync $repo/$repo.tar.gpg"
    rsync -v "$fetchdir/$(dst).tar.gpg" "$repo/$(dst).tar.gpg"
    touch "$repo/.repo"
    rm -r "$xdir"
    rm "$fetchdir/$(dst).tar"
}

disconn() {
    arg=$?
    cleanup
    fusermount -u "$repo"
    rmdir "$repo"
    rm -r "$fetchdir"
    exit $arg
}

main() {
    test -n "$1" || usage
    test -n "$2" || usage

    isfull=0
    cmd="$1"
    case "$2" in
        *:*)
            fetchdir=$(mktemp -d)
            repo=$(mktemp -d)
            sshfs "$2" "$repo" || exits "error connecting with server; check auth"
            trap disconn EXIT
            ;;
        *)
            repo="$(realpath ${2%/})"
            fetchdir="${repo}"
            trap cleanup EXIT
            ;;
    esac
    shift 2
    test -e "$repo/.lock" && exits "backup repository is locked; either wait for job to finish or delete .lock"
    touch "$repo/.lock" || exits "couldn't create lock file"
    case "$cmd" in
        f*) isfull=1; backup  "$@"; exit;;
        i*) is_repo;  backup  "$@"; exit;;
        r*) is_repo;  restore "$@"; exit;;
        l*) is_repo;  list    "$@"; exit;;
        *) exits "invalid operation: $cmd";;
    esac
}

main "$@"
